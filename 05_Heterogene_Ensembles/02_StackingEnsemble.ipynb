{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, VotingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import combinations \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Set a random state\n",
    "rs = 4\n",
    "\n",
    "#Set our CVs\n",
    "cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs)\n",
    "cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=rs)\n",
    "\n",
    "#Set the scaler\n",
    "scaler = PowerTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 entries removed due to errors in feature 'scannedLineItemsPerSecond'.\n"
     ]
    }
   ],
   "source": [
    "#Get current directory \n",
    "path = os.getcwd() \n",
    "\n",
    "#Get parent directory \n",
    "parent = os.path.dirname(path)\n",
    "\n",
    "#Move to the directory with data\n",
    "train_csv = os.path.join(parent, \"data\", \"train.csv\")\n",
    "\n",
    "#Import our dataset\n",
    "dataset = pd.read_csv(train_csv, delimiter = '|')\n",
    "\n",
    "#Clean the dataset (drop unrealistic entries)\n",
    "dataset_org = dataset.copy()\n",
    "dataset = dataset[dataset['scannedLineItemsPerSecond'] < 4]\n",
    "cutted = len(dataset_org)-len(dataset)\n",
    "print(f\"{cutted} entries removed due to errors in feature 'scannedLineItemsPerSecond'.\")\n",
    "\n",
    "#Add new feature 'totalItems'\n",
    "dataset = dataset.assign(totalItems = dataset.totalScanTimeInSeconds * dataset.scannedLineItemsPerSecond)\n",
    "\n",
    "#Add new feature 'suspicious' as frauds only occur at trustLevels 1-2, all others are non-fraudulent\n",
    "suspicious = dataset['trustLevel'].copy()\n",
    "suspicious[suspicious > 2] = 3\n",
    "dataset = dataset.assign(suspicious = suspicious)\n",
    "\n",
    "#Drop 'trustLevel' as it is too similar to 'suspicious'\n",
    "dataset = dataset.drop(\"trustLevel\", axis=1)\n",
    "\n",
    "#Add new feature 'avgLineItemValue'\n",
    "dataset = dataset.assign(avgLineItemValue = dataset.valuePerSecond / dataset.scannedLineItemsPerSecond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset in X and y\n",
    "X = dataset.drop('fraud', axis=1)\n",
    "y = dataset.fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>totalItems</th>\n",
       "      <th>suspicious</th>\n",
       "      <th>avgLineItemValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.886207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.954286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.781538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.183103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.019630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0                    1054       54.70              7   \n",
       "1                     108       27.36              5   \n",
       "2                    1516       62.16              3   \n",
       "3                    1791       92.31              8   \n",
       "4                     430       81.53              3   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "0                         0                      3                   0.027514   \n",
       "1                         2                      4                   0.129630   \n",
       "2                        10                      5                   0.008575   \n",
       "3                         4                      4                   0.016192   \n",
       "4                         7                      2                   0.062791   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  totalItems  suspicious  \\\n",
       "0        0.051898                  0.241379        29.0           3   \n",
       "1        0.253333                  0.357143        14.0           3   \n",
       "2        0.041003                  0.230769        13.0           3   \n",
       "3        0.051541                  0.275862        29.0           3   \n",
       "4        0.189605                  0.111111        27.0           3   \n",
       "\n",
       "   avgLineItemValue  \n",
       "0          1.886207  \n",
       "1          1.954286  \n",
       "2          4.781538  \n",
       "3          3.183103  \n",
       "4          3.019630  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define monetary_score as our used metric\n",
    "def monetary_score_func(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    monetary_value = (cm[0,0] * 0) + (cm[1, 0] * -5) + (cm[0, 1] * -25) + (cm[1, 1] * 5)\n",
    "    max_monetary_value = (cm[1,0] + cm[1,1]) * 5\n",
    "    return (monetary_value / max_monetary_value)\n",
    "\n",
    "monetary_score = make_scorer(monetary_score_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define models and parameters\n",
    "model_XG = XGBClassifier(booster=\"gblinear\", alpha=0.00075, eta=0.03, reg_lambda=0.001, n_estimators=1000, random_state=rs, n_jobs=-1)\n",
    "model_SVC = SVC(kernel=\"linear\", C=0.6, probability=True, random_state=rs)\n",
    "model_LR = LogisticRegression(solver=\"lbfgs\", C=0.3, class_weight=None, random_state=rs, n_jobs=-1)\n",
    "model_Ada = BaggingClassifier(base_estimator=AdaBoostClassifier(),\n",
    "                                   n_estimators=25, n_jobs=-1,\n",
    "                                   random_state=rs)\n",
    "\n",
    "model_MLP1 = MLPClassifier(hidden_layer_sizes=(8,4,2), alpha=1.4, max_iter=500, random_state=rs)\n",
    "model_MLP2 = MLPClassifier(hidden_layer_sizes=(8,4,2), alpha=1.5, max_iter=500, random_state=rs)\n",
    "model_MLP3 = MLPClassifier(hidden_layer_sizes=(8,4),   alpha=1.3, max_iter=500, random_state=rs, learning_rate_init=0.005)\n",
    "\n",
    "estimators_MLP = [\n",
    "    (\"MLP1\", model_MLP1),\n",
    "    (\"MLP2\", model_MLP2),\n",
    "    (\"MLP3\", model_MLP3)\n",
    "]\n",
    "model_MLP = VotingClassifier(estimators=estimators_MLP, voting=\"soft\", n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "#Get a list of all top 5 models\n",
    "model_list = [(\"XG\", model_XG), (\"SVC\", model_SVC), (\"LR\", model_LR), (\"Ada\", model_Ada), (\"MLP\", model_MLP)]\n",
    "\n",
    "#Add combinations of 1-5 (take away combos of 1 after)\n",
    "combo5 = [com for sub in range(5) for com in combinations(model_list, sub + 1)] \n",
    "combo1 = [com for sub in range(1) for com in combinations(model_list, sub + 1)]\n",
    "combos = list(set(combo5) - set(combo1))\n",
    "\n",
    "print(len(combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('XG', XGBClassifier(alpha=0.00075, base_score=None, booster='gblinear',\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, eta=0.03, gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=4, reg_alpha=None, reg_lambda=0.001,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)), ('LR', LogisticRegression(C=0.3, n_jobs=-1, random_state=4)), ('Ada', BaggingClassifier(base_estimator=AdaBoostClassifier(), n_estimators=25,\n",
      "                  n_jobs=-1, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft')))\n"
     ]
    }
   ],
   "source": [
    "#What does a combo element look like?\n",
    "print(combos[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dummy, as estimators is a mandatory parameter\n",
    "models_SLA = (\n",
    "    (\"SVC\", model_SVC),  \n",
    "    (\"LR\", model_LR),   \n",
    "    (\"Ada\", model_Ada)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', PowerTransformer()),\n",
      "                ('model',\n",
      "                 StackingClassifier(estimators=(('SVC',\n",
      "                                                 SVC(C=0.6, kernel='linear',\n",
      "                                                     probability=True,\n",
      "                                                     random_state=4)),\n",
      "                                                ('LR',\n",
      "                                                 LogisticRegression(C=0.3,\n",
      "                                                                    n_jobs=-1,\n",
      "                                                                    random_state=4)),\n",
      "                                                ('Ada',\n",
      "                                                 BaggingClassifier(base_estimator=AdaBoostClassifier(),\n",
      "                                                                   n_estimators=25,\n",
      "                                                                   n_jobs=-1,\n",
      "                                                                   random_state=4))),\n",
      "                                    n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "#Define model and parameters\n",
    "model = StackingClassifier(estimators=models_SLA, n_jobs=-1)\n",
    "params = {\"model__estimators\": combos,\n",
    "          \"model__final_estimator\": [model_XG, model_SVC, model_LR, model_Ada, model_MLP]\n",
    "         }\n",
    "\n",
    "#Create the model pipeline\n",
    "try:\n",
    "    pipe_model = Pipeline([\n",
    "        ('sampler', sampler),\n",
    "        (\"scaler\", scaler),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "except NameError:\n",
    "    pipe_model = Pipeline([    \n",
    "        (\"scaler\", scaler),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "#Define the grid search (inner cv)\n",
    "grid = GridSearchCV(estimator=pipe_model, param_grid=params, scoring=monetary_score, cv=cv_inner, n_jobs=-1)\n",
    "print(pipe_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data to the GridSearch\n",
    "grid.fit(X, y)\n",
    "\n",
    "#Get the GridSearch results\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "#Sort the output by mean_test_score\n",
    "results.sort_values(by='mean_test_score', inplace=True, ignore_index=True, ascending=False)\n",
    "\n",
    "#Drop everything but the param columns\n",
    "results_grid = results.drop([\"mean_fit_time\", \"std_fit_time\", \"mean_score_time\", \"std_score_time\", \"split0_test_score\", \"split1_test_score\", \"split2_test_score\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"], axis=1)\n",
    "\n",
    "#Get back mean_test_score and std_test_score (as double_std_test_score) to insert them in the first two columns\n",
    "results_grid.insert(0, \"mean_test_score\", results[\"mean_test_score\"])\n",
    "results_grid.insert(1, \"double_std_test_score\", results[\"std_test_score\"] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results so we can look at them again later\n",
    "results_grid.to_pickle(\"stacking_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the results if we want to look at them without running the whole code again\n",
    "#results_grid = pd.read_pickle(\"stacking_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>double_std_test_score</th>\n",
       "      <th>param_model__estimators</th>\n",
       "      <th>param_model__final_estimator</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.538375</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>LogisticRegression(C=0.3, n_jobs=-1, random_st...</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.557983</td>\n",
       "      <td>0.042783</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>LogisticRegression(C=0.3, n_jobs=-1, random_st...</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.634734</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>LogisticRegression(C=0.3, n_jobs=-1, random_st...</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.489916</td>\n",
       "      <td>0.068928</td>\n",
       "      <td>((LR, LogisticRegression(C=0.3, n_jobs=-1, ran...</td>\n",
       "      <td>SVC(C=0.6, kernel='linear', probability=True, ...</td>\n",
       "      <td>{'model__estimators': (('LR', LogisticRegressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.538936</td>\n",
       "      <td>0.083892</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>LogisticRegression(C=0.3, n_jobs=-1, random_st...</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.594398</td>\n",
       "      <td>0.492987</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>VotingClassifier(estimators=[('MLP1',\\n       ...</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.536695</td>\n",
       "      <td>0.493819</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>XGBClassifier(alpha=0.00075, base_score=None, ...</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.594958</td>\n",
       "      <td>0.498621</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>VotingClassifier(estimators=[('MLP1',\\n       ...</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.575350</td>\n",
       "      <td>0.520776</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>VotingClassifier(estimators=[('MLP1',\\n       ...</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.575350</td>\n",
       "      <td>0.520776</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>VotingClassifier(estimators=[('MLP1',\\n       ...</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  double_std_test_score  \\\n",
       "59         0.538375               0.012676   \n",
       "50         0.557983               0.042783   \n",
       "10         0.634734               0.049806   \n",
       "78         0.489916               0.068928   \n",
       "57         0.538936               0.083892   \n",
       "..              ...                    ...   \n",
       "33         0.594398               0.492987   \n",
       "60         0.536695               0.493819   \n",
       "32         0.594958               0.498621   \n",
       "42         0.575350               0.520776   \n",
       "43         0.575350               0.520776   \n",
       "\n",
       "                              param_model__estimators  \\\n",
       "59  ((SVC, SVC(C=0.6, kernel='linear', probability...   \n",
       "50  ((SVC, SVC(C=0.6, kernel='linear', probability...   \n",
       "10  ((XG, XGBClassifier(alpha=0.00075, base_score=...   \n",
       "78  ((LR, LogisticRegression(C=0.3, n_jobs=-1, ran...   \n",
       "57  ((XG, XGBClassifier(alpha=0.00075, base_score=...   \n",
       "..                                                ...   \n",
       "33  ((XG, XGBClassifier(alpha=0.00075, base_score=...   \n",
       "60  ((XG, XGBClassifier(alpha=0.00075, base_score=...   \n",
       "32  ((XG, XGBClassifier(alpha=0.00075, base_score=...   \n",
       "42  ((SVC, SVC(C=0.6, kernel='linear', probability...   \n",
       "43  ((XG, XGBClassifier(alpha=0.00075, base_score=...   \n",
       "\n",
       "                         param_model__final_estimator  \\\n",
       "59  LogisticRegression(C=0.3, n_jobs=-1, random_st...   \n",
       "50  LogisticRegression(C=0.3, n_jobs=-1, random_st...   \n",
       "10  LogisticRegression(C=0.3, n_jobs=-1, random_st...   \n",
       "78  SVC(C=0.6, kernel='linear', probability=True, ...   \n",
       "57  LogisticRegression(C=0.3, n_jobs=-1, random_st...   \n",
       "..                                                ...   \n",
       "33  VotingClassifier(estimators=[('MLP1',\\n       ...   \n",
       "60  XGBClassifier(alpha=0.00075, base_score=None, ...   \n",
       "32  VotingClassifier(estimators=[('MLP1',\\n       ...   \n",
       "42  VotingClassifier(estimators=[('MLP1',\\n       ...   \n",
       "43  VotingClassifier(estimators=[('MLP1',\\n       ...   \n",
       "\n",
       "                                               params  \n",
       "59  {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "50  {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "10  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "78  {'model__estimators': (('LR', LogisticRegressi...  \n",
       "57  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "..                                                ...  \n",
       "33  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "60  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "32  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "42  {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "43  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "\n",
       "[80 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the top results (sorted by 'mean_test_score')\n",
    "#results_grid[:20]\n",
    "\n",
    "#See the top results (sorted by 'double_std_test_score')\n",
    "results_grid[:80].sort_values(by='double_std_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__estimators': (('SVC', SVC(C=0.6, kernel='linear', probability=True, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft'))), 'model__final_estimator': LogisticRegression(C=0.3, n_jobs=-1, random_state=4)}\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[59, \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__estimators': (('XG', XGBClassifier(alpha=0.00075, base_score=None, booster='gblinear',\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, eta=0.03, gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=4, reg_alpha=None, reg_lambda=0.001,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)), ('SVC', SVC(C=0.6, kernel='linear', probability=True, random_state=4)), ('LR', LogisticRegression(C=0.3, n_jobs=-1, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft'))), 'model__final_estimator': LogisticRegression(C=0.3, n_jobs=-1, random_state=4)}\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[10, \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__estimators': (('XG', XGBClassifier(alpha=0.00075, base_score=None, booster='gblinear',\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, eta=0.03, gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=4, reg_alpha=None, reg_lambda=0.001,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)), ('SVC', SVC(C=0.6, kernel='linear', probability=True, random_state=4)), ('LR', LogisticRegression(C=0.3, n_jobs=-1, random_state=4)), ('Ada', BaggingClassifier(base_estimator=AdaBoostClassifier(), n_estimators=25,\n",
      "                  n_jobs=-1, random_state=4))), 'model__final_estimator': LogisticRegression(C=0.3, n_jobs=-1, random_state=4)}\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[3, \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__estimators': (('XG', XGBClassifier(alpha=0.00075, base_score=None, booster='gblinear',\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, eta=0.03, gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=4, reg_alpha=None, reg_lambda=0.001,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)), ('SVC', SVC(C=0.6, kernel='linear', probability=True, random_state=4)), ('LR', LogisticRegression(C=0.3, n_jobs=-1, random_state=4)), ('Ada', BaggingClassifier(base_estimator=AdaBoostClassifier(), n_estimators=25,\n",
      "                  n_jobs=-1, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft'))), 'model__final_estimator': LogisticRegression(C=0.3, n_jobs=-1, random_state=4)}\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[4, \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__estimators': (('Ada', BaggingClassifier(base_estimator=AdaBoostClassifier(), n_estimators=25,\n",
      "                  n_jobs=-1, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft'))), 'model__final_estimator': VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft')}\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[0, \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', PowerTransformer()),\n",
       "                ('model',\n",
       "                 StackingClassifier(estimators=(('XG',\n",
       "                                                 XGBClassifier(alpha=0.00075,\n",
       "                                                               base_score=None,\n",
       "                                                               booster='gblinear',\n",
       "                                                               colsample_bylevel=None,\n",
       "                                                               colsample_bynode=None,\n",
       "                                                               colsample_bytree=None,\n",
       "                                                               eta=0.03,\n",
       "                                                               gamma=None,\n",
       "                                                               gpu_id=None,\n",
       "                                                               importance_type='gain',\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_d...\n",
       "                                                                                             hidden_layer_sizes=(8,\n",
       "                                                                                                                 4,\n",
       "                                                                                                                 2),\n",
       "                                                                                             max_iter=500,\n",
       "                                                                                             random_state=4)),\n",
       "                                                                              ('MLP2',\n",
       "                                                                               MLPClassifier(alpha=1.5,\n",
       "                                                                                             hidden_layer_sizes=(8,\n",
       "                                                                                                                 4,\n",
       "                                                                                                                 2),\n",
       "                                                                                             max_iter=500,\n",
       "                                                                                             random_state=4)),\n",
       "                                                                              ('MLP3',\n",
       "                                                                               MLPClassifier(alpha=1.3,\n",
       "                                                                                             hidden_layer_sizes=(8,\n",
       "                                                                                                                 4),\n",
       "                                                                                             learning_rate_init=0.005,\n",
       "                                                                                             max_iter=500,\n",
       "                                                                                             random_state=4))],\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  voting='soft'))),\n",
       "                                    final_estimator=LogisticRegression(C=0.3,\n",
       "                                                                       n_jobs=-1,\n",
       "                                                                       random_state=4),\n",
       "                                    n_jobs=-1))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternative A - use best model as final_clf\n",
    "final_pipe = clone(pipe_model)\n",
    "final_pipe = final_pipe.set_params(**results_grid.loc[10, \"params\"])\n",
    "final_pipe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
