{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from itertools import combinations \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Set a random state\n",
    "rs = 4\n",
    "\n",
    "#Set our CVs\n",
    "cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=rs)\n",
    "cv_inner = StratifiedKFold(n_splits=3, shuffle=True, random_state=rs)\n",
    "\n",
    "#Set the scaler\n",
    "scaler = PowerTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 entries removed due to errors in feature 'scannedLineItemsPerSecond'.\n"
     ]
    }
   ],
   "source": [
    "#Get current directory \n",
    "path = os.getcwd() \n",
    "\n",
    "#Get parent directory \n",
    "parent = os.path.dirname(path)\n",
    "\n",
    "#Move to the directory with data\n",
    "train_csv = os.path.join(parent, \"data\", \"train.csv\")\n",
    "\n",
    "#Import our dataset\n",
    "dataset = pd.read_csv(train_csv, delimiter = '|')\n",
    "\n",
    "#Clean the dataset (drop unrealistic entries)\n",
    "dataset_org = dataset.copy()\n",
    "dataset = dataset[dataset['scannedLineItemsPerSecond'] < 4]\n",
    "cutted = len(dataset_org)-len(dataset)\n",
    "print(f\"{cutted} entries removed due to errors in feature 'scannedLineItemsPerSecond'.\")\n",
    "\n",
    "#Add new feature 'totalItems'\n",
    "dataset = dataset.assign(totalItems = dataset.totalScanTimeInSeconds * dataset.scannedLineItemsPerSecond)\n",
    "\n",
    "#Add new feature 'suspicious' as frauds only occur at trustLevels 1-2, all others are non-fraudulent\n",
    "suspicious = dataset['trustLevel'].copy()\n",
    "suspicious[suspicious > 2] = 3\n",
    "dataset = dataset.assign(suspicious = suspicious)\n",
    "\n",
    "#Drop 'trustLevel' as it is too similar to 'suspicious'\n",
    "dataset = dataset.drop(\"trustLevel\", axis=1)\n",
    "\n",
    "#Add new feature 'avgLineItemValue'\n",
    "dataset = dataset.assign(avgLineItemValue = dataset.valuePerSecond / dataset.scannedLineItemsPerSecond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset in X and y\n",
    "X = dataset.drop('fraud', axis=1)\n",
    "y = dataset.fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>totalItems</th>\n",
       "      <th>suspicious</th>\n",
       "      <th>avgLineItemValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.886207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.954286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.781538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.183103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.019630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0                    1054       54.70              7   \n",
       "1                     108       27.36              5   \n",
       "2                    1516       62.16              3   \n",
       "3                    1791       92.31              8   \n",
       "4                     430       81.53              3   \n",
       "\n",
       "   scansWithoutRegistration  quantityModifications  scannedLineItemsPerSecond  \\\n",
       "0                         0                      3                   0.027514   \n",
       "1                         2                      4                   0.129630   \n",
       "2                        10                      5                   0.008575   \n",
       "3                         4                      4                   0.016192   \n",
       "4                         7                      2                   0.062791   \n",
       "\n",
       "   valuePerSecond  lineItemVoidsPerPosition  totalItems  suspicious  \\\n",
       "0        0.051898                  0.241379        29.0           3   \n",
       "1        0.253333                  0.357143        14.0           3   \n",
       "2        0.041003                  0.230769        13.0           3   \n",
       "3        0.051541                  0.275862        29.0           3   \n",
       "4        0.189605                  0.111111        27.0           3   \n",
       "\n",
       "   avgLineItemValue  \n",
       "0          1.886207  \n",
       "1          1.954286  \n",
       "2          4.781538  \n",
       "3          3.183103  \n",
       "4          3.019630  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define monetary_score as our used metric\n",
    "def monetary_score_func(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    monetary_value = (cm[0,0] * 0) + (cm[1, 0] * -5) + (cm[0, 1] * -25) + (cm[1, 1] * 5)\n",
    "    max_monetary_value = (cm[1,0] + cm[1,1]) * 5\n",
    "    return (monetary_value / max_monetary_value)\n",
    "\n",
    "monetary_score = make_scorer(monetary_score_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define models and parameters\n",
    "model_XG = XGBClassifier(booster=\"gblinear\", alpha=0.00075, eta=0.03, reg_lambda=0.001, n_estimators=1000, random_state=rs, n_jobs=-1)\n",
    "model_SVC = SVC(kernel=\"linear\", C=0.6, probability=True, random_state=rs)\n",
    "model_LR = LogisticRegression(solver=\"lbfgs\", C=0.3, class_weight=None, random_state=rs, n_jobs=-1)\n",
    "model_Ada = BaggingClassifier(base_estimator=AdaBoostClassifier(),\n",
    "                                   n_estimators=25, n_jobs=-1,\n",
    "                                   random_state=rs)\n",
    "\n",
    "model_MLP1 = MLPClassifier(hidden_layer_sizes=(8,4,2), alpha=1.4, max_iter=500, random_state=rs)\n",
    "model_MLP2 = MLPClassifier(hidden_layer_sizes=(8,4,2), alpha=1.5, max_iter=500, random_state=rs)\n",
    "model_MLP3 = MLPClassifier(hidden_layer_sizes=(8,4),   alpha=1.3, max_iter=500, random_state=rs, learning_rate_init=0.005)\n",
    "\n",
    "estimators_MLP = [\n",
    "    (\"MLP1\", model_MLP1),\n",
    "    (\"MLP2\", model_MLP2),\n",
    "    (\"MLP3\", model_MLP3)\n",
    "]\n",
    "\n",
    "model_MLP = VotingClassifier(estimators=estimators_MLP, voting=\"soft\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#Get a list of all top 5 models\n",
    "model_list = [(\"XG\", model_XG), (\"SVC\", model_SVC), (\"LR\", model_LR), (\"Ada\", model_Ada), (\"MLP\", model_MLP)]\n",
    "\n",
    "#Only add combinations of 3 (take away combos of 1-2 after)\n",
    "combo3 = [com for sub in range(3) for com in combinations(model_list, sub + 1)] \n",
    "combo2 = [com for sub in range(3 - 1) for com in combinations(model_list, sub + 1)]\n",
    "combos = list(set(combo3) - set(combo2))\n",
    "\n",
    "print(len(combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "#Add the combination of 5 to combos\n",
    "models_all = (\n",
    "    (\"XG\", model_XG),\n",
    "    (\"LR\", model_LR),   \n",
    "    (\"Ada\", model_Ada),\n",
    "    (\"SVC\", model_SVC),   \n",
    "    (\"MLP\", model_MLP)\n",
    "             )\n",
    "\n",
    "combos.append(models_all)\n",
    "print(len(combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', PowerTransformer()),\n",
      "                ('model',\n",
      "                 VotingClassifier(estimators=(('XG',\n",
      "                                               XGBClassifier(alpha=0.00075,\n",
      "                                                             base_score=None,\n",
      "                                                             booster='gblinear',\n",
      "                                                             colsample_bylevel=None,\n",
      "                                                             colsample_bynode=None,\n",
      "                                                             colsample_bytree=None,\n",
      "                                                             eta=0.03,\n",
      "                                                             gamma=None,\n",
      "                                                             gpu_id=None,\n",
      "                                                             importance_type='gain',\n",
      "                                                             interaction_constraints=None,\n",
      "                                                             learning_rate=None,\n",
      "                                                             max_delta_step=None,\n",
      "                                                             max_dep...\n",
      "                                               VotingClassifier(estimators=[('MLP1',\n",
      "                                                                             MLPClassifier(alpha=1.4,\n",
      "                                                                                           hidden_layer_sizes=(8,\n",
      "                                                                                                               4,\n",
      "                                                                                                               2),\n",
      "                                                                                           max_iter=500,\n",
      "                                                                                           random_state=4)),\n",
      "                                                                            ('MLP2',\n",
      "                                                                             MLPClassifier(alpha=1.5,\n",
      "                                                                                           hidden_layer_sizes=(8,\n",
      "                                                                                                               4,\n",
      "                                                                                                               2),\n",
      "                                                                                           max_iter=500,\n",
      "                                                                                           random_state=4)),\n",
      "                                                                            ('MLP3',\n",
      "                                                                             MLPClassifier(alpha=1.3,\n",
      "                                                                                           hidden_layer_sizes=(8,\n",
      "                                                                                                               4),\n",
      "                                                                                           learning_rate_init=0.005,\n",
      "                                                                                           max_iter=500,\n",
      "                                                                                           random_state=4))],\n",
      "                                                                n_jobs=-1,\n",
      "                                                                voting='soft'))),\n",
      "                                  n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "#Define model and parameters\n",
    "model = VotingClassifier(estimators=models_all, n_jobs=-1)\n",
    "params = {\"model__estimators\": combos,\n",
    "          \"model__voting\": [\"soft\", \"hard\"]\n",
    "         }\n",
    "\n",
    "#Create the model pipeline\n",
    "try:\n",
    "    pipe_model = Pipeline([\n",
    "        ('sampler', sampler),\n",
    "        (\"scaler\", scaler),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "except NameError:\n",
    "    pipe_model = Pipeline([    \n",
    "        (\"scaler\", scaler),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "#Define the grid search (inner cv)\n",
    "grid = GridSearchCV(estimator=pipe_model, param_grid=params, scoring=monetary_score, cv=cv_inner, n_jobs=-1)\n",
    "print(pipe_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the data to the GridSearch\n",
    "grid.fit(X, y)\n",
    "\n",
    "#Get the GridSearch results\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "#Sort the output by mean_test_score\n",
    "results.sort_values(by='mean_test_score', inplace=True, ignore_index=True, ascending=False)\n",
    "\n",
    "#Drop everything but the param columns\n",
    "results_grid = results.drop([\"mean_fit_time\", \"std_fit_time\", \"mean_score_time\", \"std_score_time\", \"split0_test_score\", \"split1_test_score\", \"split2_test_score\", \"rank_test_score\", \"mean_test_score\", \"std_test_score\"], axis=1)\n",
    "\n",
    "#Get back mean_test_score and std_test_score (as double_std_test_score) to insert them in the first two columns\n",
    "results_grid.insert(0, \"mean_test_score\", results[\"mean_test_score\"])\n",
    "results_grid.insert(1, \"double_std_test_score\", results[\"std_test_score\"] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>double_std_test_score</th>\n",
       "      <th>param_model__estimators</th>\n",
       "      <th>param_model__voting</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750140</td>\n",
       "      <td>0.234192</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.731092</td>\n",
       "      <td>0.192587</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.186796</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.186796</td>\n",
       "      <td>((LR, LogisticRegression(C=0.3, n_jobs=-1, ran...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('LR', LogisticRegressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.711485</td>\n",
       "      <td>0.186796</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.662465</td>\n",
       "      <td>0.315991</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.244407</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.244407</td>\n",
       "      <td>((LR, LogisticRegression(C=0.3, n_jobs=-1, ran...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('LR', LogisticRegressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.244407</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.652941</td>\n",
       "      <td>0.331193</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.211649</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.211649</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.624370</td>\n",
       "      <td>0.384594</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.616246</td>\n",
       "      <td>0.188841</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.615406</td>\n",
       "      <td>0.303287</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.576751</td>\n",
       "      <td>0.257863</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.575350</td>\n",
       "      <td>0.520776</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.575350</td>\n",
       "      <td>0.439136</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.557703</td>\n",
       "      <td>0.209962</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>hard</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.556303</td>\n",
       "      <td>0.467021</td>\n",
       "      <td>((XG, XGBClassifier(alpha=0.00075, base_score=...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('XG', XGBClassifier(al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.556303</td>\n",
       "      <td>0.467021</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.537255</td>\n",
       "      <td>0.413298</td>\n",
       "      <td>((SVC, SVC(C=0.6, kernel='linear', probability...</td>\n",
       "      <td>soft</td>\n",
       "      <td>{'model__estimators': (('SVC', SVC(C=0.6, kern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  double_std_test_score  \\\n",
       "0          0.750140               0.234192   \n",
       "1          0.731092               0.192587   \n",
       "2          0.711485               0.186796   \n",
       "3          0.711485               0.186796   \n",
       "4          0.711485               0.186796   \n",
       "5          0.662465               0.315991   \n",
       "6          0.654342               0.244407   \n",
       "7          0.654342               0.244407   \n",
       "8          0.654342               0.244407   \n",
       "9          0.652941               0.331193   \n",
       "10         0.635294               0.211649   \n",
       "11         0.635294               0.211649   \n",
       "12         0.624370               0.384594   \n",
       "13         0.616246               0.188841   \n",
       "14         0.615406               0.303287   \n",
       "15         0.576751               0.257863   \n",
       "16         0.575350               0.520776   \n",
       "17         0.575350               0.439136   \n",
       "18         0.557703               0.209962   \n",
       "19         0.556303               0.467021   \n",
       "20         0.556303               0.467021   \n",
       "21         0.537255               0.413298   \n",
       "\n",
       "                              param_model__estimators param_model__voting  \\\n",
       "0   ((XG, XGBClassifier(alpha=0.00075, base_score=...                hard   \n",
       "1   ((SVC, SVC(C=0.6, kernel='linear', probability...                hard   \n",
       "2   ((XG, XGBClassifier(alpha=0.00075, base_score=...                hard   \n",
       "3   ((LR, LogisticRegression(C=0.3, n_jobs=-1, ran...                hard   \n",
       "4   ((XG, XGBClassifier(alpha=0.00075, base_score=...                hard   \n",
       "5   ((XG, XGBClassifier(alpha=0.00075, base_score=...                soft   \n",
       "6   ((XG, XGBClassifier(alpha=0.00075, base_score=...                soft   \n",
       "7   ((LR, LogisticRegression(C=0.3, n_jobs=-1, ran...                soft   \n",
       "8   ((XG, XGBClassifier(alpha=0.00075, base_score=...                soft   \n",
       "9   ((XG, XGBClassifier(alpha=0.00075, base_score=...                soft   \n",
       "10  ((XG, XGBClassifier(alpha=0.00075, base_score=...                hard   \n",
       "11  ((XG, XGBClassifier(alpha=0.00075, base_score=...                hard   \n",
       "12  ((SVC, SVC(C=0.6, kernel='linear', probability...                soft   \n",
       "13  ((XG, XGBClassifier(alpha=0.00075, base_score=...                hard   \n",
       "14  ((SVC, SVC(C=0.6, kernel='linear', probability...                hard   \n",
       "15  ((XG, XGBClassifier(alpha=0.00075, base_score=...                hard   \n",
       "16  ((XG, XGBClassifier(alpha=0.00075, base_score=...                soft   \n",
       "17  ((XG, XGBClassifier(alpha=0.00075, base_score=...                soft   \n",
       "18  ((SVC, SVC(C=0.6, kernel='linear', probability...                hard   \n",
       "19  ((XG, XGBClassifier(alpha=0.00075, base_score=...                soft   \n",
       "20  ((SVC, SVC(C=0.6, kernel='linear', probability...                soft   \n",
       "21  ((SVC, SVC(C=0.6, kernel='linear', probability...                soft   \n",
       "\n",
       "                                               params  \n",
       "0   {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "1   {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "2   {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "3   {'model__estimators': (('LR', LogisticRegressi...  \n",
       "4   {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "5   {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "6   {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "7   {'model__estimators': (('LR', LogisticRegressi...  \n",
       "8   {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "9   {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "10  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "11  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "12  {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "13  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "14  {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "15  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "16  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "17  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "18  {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "19  {'model__estimators': (('XG', XGBClassifier(al...  \n",
       "20  {'model__estimators': (('SVC', SVC(C=0.6, kern...  \n",
       "21  {'model__estimators': (('SVC', SVC(C=0.6, kern...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See the top results (sorted by 'mean_test_score')\n",
    "results_grid\n",
    "\n",
    "#See the top results (sorted by 'double_std_test_score')\n",
    "#results_grid.sort_values(by='double_std_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results so we can look at them again later\n",
    "results_grid.to_pickle(\"voting_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the results if we want to look at them without running the whole code again\n",
    "#results_grid = pd.read_pickle(\"voting_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('XG', XGBClassifier(alpha=0.00075, base_score=None, booster='gblinear',\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, eta=0.03, gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=4, reg_alpha=None, reg_lambda=0.001,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)), ('SVC', SVC(C=0.6, kernel='linear', probability=True, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft')))\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[0, \"param_model__estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('SVC', SVC(C=0.6, kernel='linear', probability=True, random_state=4)), ('LR', LogisticRegression(C=0.3, n_jobs=-1, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft')))\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[1, \"param_model__estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('XG', XGBClassifier(alpha=0.00075, base_score=None, booster='gblinear',\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, eta=0.03, gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=4, reg_alpha=None, reg_lambda=0.001,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)), ('Ada', BaggingClassifier(base_estimator=AdaBoostClassifier(), n_estimators=25,\n",
      "                  n_jobs=-1, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft')))\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[2, \"param_model__estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('LR', LogisticRegression(C=0.3, n_jobs=-1, random_state=4)), ('Ada', BaggingClassifier(base_estimator=AdaBoostClassifier(), n_estimators=25,\n",
      "                  n_jobs=-1, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft')))\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[3, \"param_model__estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('XG', XGBClassifier(alpha=0.00075, base_score=None, booster='gblinear',\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, eta=0.03, gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=1000, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=4, reg_alpha=None, reg_lambda=0.001,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)), ('LR', LogisticRegression(C=0.3, n_jobs=-1, random_state=4)), ('Ada', BaggingClassifier(base_estimator=AdaBoostClassifier(), n_estimators=25,\n",
      "                  n_jobs=-1, random_state=4)), ('SVC', SVC(C=0.6, kernel='linear', probability=True, random_state=4)), ('MLP', VotingClassifier(estimators=[('MLP1',\n",
      "                              MLPClassifier(alpha=1.4,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP2',\n",
      "                              MLPClassifier(alpha=1.5,\n",
      "                                            hidden_layer_sizes=(8, 4, 2),\n",
      "                                            max_iter=500, random_state=4)),\n",
      "                             ('MLP3',\n",
      "                              MLPClassifier(alpha=1.3,\n",
      "                                            hidden_layer_sizes=(8, 4),\n",
      "                                            learning_rate_init=0.005,\n",
      "                                            max_iter=500, random_state=4))],\n",
      "                 n_jobs=-1, voting='soft')))\n"
     ]
    }
   ],
   "source": [
    "print(results_grid.loc[4, \"param_model__estimators\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', PowerTransformer()),\n",
       "                ('model',\n",
       "                 VotingClassifier(estimators=(('SVC',\n",
       "                                               SVC(C=0.6, kernel='linear',\n",
       "                                                   probability=True,\n",
       "                                                   random_state=4)),\n",
       "                                              ('LR',\n",
       "                                               LogisticRegression(C=0.3,\n",
       "                                                                  n_jobs=-1,\n",
       "                                                                  random_state=4)),\n",
       "                                              ('MLP',\n",
       "                                               VotingClassifier(estimators=[('MLP1',\n",
       "                                                                             MLPClassifier(alpha=1.4,\n",
       "                                                                                           hidden_layer_sizes=(8,\n",
       "                                                                                                               4,\n",
       "                                                                                                               2),\n",
       "                                                                                           max_iter=500,\n",
       "                                                                                           random_state=4)),\n",
       "                                                                            ('MLP2',\n",
       "                                                                             MLPClassifier(alpha=1.5,\n",
       "                                                                                           hidden_layer_sizes=(8,\n",
       "                                                                                                               4,\n",
       "                                                                                                               2),\n",
       "                                                                                           max_iter=500,\n",
       "                                                                                           random_state=4)),\n",
       "                                                                            ('MLP3',\n",
       "                                                                             MLPClassifier(alpha=1.3,\n",
       "                                                                                           hidden_layer_sizes=(8,\n",
       "                                                                                                               4),\n",
       "                                                                                           learning_rate_init=0.005,\n",
       "                                                                                           max_iter=500,\n",
       "                                                                                           random_state=4))],\n",
       "                                                                n_jobs=-1,\n",
       "                                                                voting='soft'))),\n",
       "                                  n_jobs=-1))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternative A - use best model as final_clf\n",
    "final_pipe = clone(pipe_model)\n",
    "final_pipe = final_pipe.set_params(**results_grid.loc[1, \"params\"])\n",
    "final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
